# ğŸ“˜ Phase 1: Understanding Gradient Descent

---

## ğŸ¯ What is Gradient Descent?

Gradient Descent is a **first-order iterative optimization algorithm** used to find the **minimum of a function**.

In machine learning, itâ€™s commonly used to **minimize the loss function** by updating model parameters in the direction that most reduces the loss â€” the **negative of the gradient**.

---

## âš™ï¸ The Update Rule (1D)

Given a function `f(x)`, the gradient descent update rule is:

$$
x_{\text{new}} = x_{\text{old}} - \alpha \cdot \frac{df}{dx}
$$

Where:
- $ x $ is the current position
- $ \alpha $ is the **learning rate**
- $ \frac{df}{dx} $ is the derivative (slope) at point $ x $

---

## ğŸ“‰ Example: `f(x) = xÂ²`

To minimize this function using gradient descent:

### ğŸ”¢ Step-by-Step Derivation

$$
\frac{df}{dx} = 2x
$$

So, the update rule becomes:

$$
x_{\text{new}} = x - \alpha \cdot 2x = x(1 - 2\alpha)
$$

> ğŸ” This leads to exponential decay towards the minimum at 0.

---

## ğŸ“Š Image Prompt

**Prompt**:  
Plot the function `f(x) = xÂ²` with a red dot showing descent steps from `x = 4 â†’ 0`. Annotate each step: "Step 0", "Step 1", ..., "Converged".

---

## âš ï¸ Why Learning Rate Matters

### ğŸ¯ Good Learning Rate

A good Î± is small enough to converge smoothly and large enough to converge fast.

**Prompt**:  
Overlay 3 descent paths with:
- Î± = 0.01 â†’ slow convergence  
- Î± = 0.1 â†’ good convergence  
- Î± = 1.2 â†’ diverges

Use labeled points and arrows.

---

## ğŸ”„ Extending to 2D Functions

For a function $ f(x, y) = x^2 + y^2 $, the **gradient vector** is:

$$
\nabla f = \left[ \frac{âˆ‚f}{âˆ‚x}, \frac{âˆ‚f}{âˆ‚y} \right] = [2x, 2y]
$$

Update rule becomes:

$$
\vec{x}_{\text{new}} = \vec{x}_{\text{old}} - \alpha \cdot \nabla f
$$

---

### ğŸ§® 2D Descent Example

Start at point $(x = 2, y = 2)$, learning rate $ \alpha = 0.1 $

1. $ \nabla f = (4, 4) $
2. New point = $ (2 - 0.4, 2 - 0.4) = (1.6, 1.6) $
3. Continue until convergence at $ (0, 0) $

---

## ğŸŒ„ Image Prompt

**Prompt**:  
A 3D surface plot of `f(x, y) = xÂ² + yÂ²` with a red dot descending from `(2,2)` to `(0,0)` on the bowl. Show arrows for gradients.

---

## ğŸ§  Intuition Summary

- Always **move in the negative gradient direction** (steepest descent).
- Learning rate controls **step size**.
- Too large â†’ diverges. Too small â†’ slow.
- Requires function to be **differentiable**.

---

## âœ… Recap: Key Terms

| Term           | Description                                 |
|----------------|---------------------------------------------|
| Gradient       | Direction of steepest ascent                |
| Learning Rate  | Step size in parameter space                |
| Convergence    | Reaching (local/global) minimum             |
| Loss Function  | Objective to minimize in ML                 |
| Derivative     | Slope of function at a point                |
