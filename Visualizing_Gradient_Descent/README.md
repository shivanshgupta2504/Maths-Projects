# ğŸ“‰ Visualizing Gradient Descent in Action

An interactive **Streamlit app** that visually demonstrates the **working of Gradient Descent** (and its variants) on 1D and 2D mathematical functions. Designed for learners of **Machine Learning**, **Optimization**, or **Calculus**.

---

## ğŸš€ Features Completed (Phase 1â€“5)

### âœ… Phase 1: Basic 1D Gradient Descent
- Choose from multiple **predefined 1D functions**: `xÂ²`, `sin(x)`, `|x|`, `e^x`, etc.
- Adjustable **learning rate**, **number of steps**, and **initial point (xâ‚€)**
- ğŸ“ˆ **Function plot with descent path**
- ğŸ“‰ **Loss vs Steps** graph to track convergence
- ğŸ”£ Real-time update of minimum found

---

### âœ… Phase 2: UI Enhancements & State Management
- ğŸ” Two-way synced **sliders + number input** for all values
- ğŸ§¹ **Reset button** to restore defaults for all inputs
- Clean modular layout using **`st.session_state`** for consistent behavior
- Utility abstraction for input handling (e.g., `slider_input()`)

---

### âœ… Phase 3: Function Diversity & Visualization Polish
- âœ… Support for **convex, non-convex, flat, and unstable** functions
- â• Live **LaTeX formula display** in sidebar
- ğŸ§  Final results (xâ‚˜áµ¢â‚™ and f(xâ‚˜áµ¢â‚™)) shown with annotations
- âš ï¸ Warnings for unstable learning rates (e.g., divergent sin/cubic)
- ğŸ“Š **Side-by-side layout**:
  - Left: Function descent plot
  - Right: Loss vs Steps graph

---

### âœ… Phase 4: 2D Mode and Surface/Contour Visualization
- ğŸ”€ Toggle between **1D and 2D modes**
- ğŸŒ„ 2D function support: `xÂ² + yÂ²`, `xÂ² - yÂ²`, `xÂ·sin(y)`, etc.
- ğŸŸ¦ 3D surface plots with step-wise overlay
- ğŸ”˜ Sliders for `xâ‚€`, `yâ‚€`, learning rate, and steps
- ğŸ“Œ Output shows `(x, y)` and `f(x, y)`
- ğŸ”¥ Warning messages for **non-converging** behavior (like saddle points)
- ğŸ§© Full **feature parity** with 1D version

---

### âœ… Phase 5: Animations & Optimizer Comparisons
- ğŸŒ€ Toggle to **enable/disable animation**
- ğŸï¸ **1D animated descent path** (GIF via Matplotlib + Pillow)
- ğŸŒ **2D Contour path animation** of optimization journey
- ğŸ§  Select from **4 optimizers**:
  - Gradient Descent (Vanilla)
  - Momentum
  - RMSprop
  - Adam
- âš™ï¸ Optimizer-specific sliders:
  - Momentum Î²
  - RMSprop: decay rate (Ï), epsilon (Îµ)
  - Adam: Î²â‚, Î²â‚‚, epsilon (Îµ)
- ğŸ›ï¸ All hyperparameters adjustable via sliders (no number boxes)
- ğŸ¯ Animations run in **sync** for both descent and loss graphs
- âœ… Modular engine design: logic separated into `gd_engine.py`, supports multiple optimizers

---

## ğŸ§  Concepts Demonstrated

- Gradient Descent Optimization (1D & 2D)
- Loss vs Epoch (Convergence Graph)
- Effect of Learning Rate on Descent Stability
- Role of Momentum, RMSprop, and Adam optimizers
- Local Minima vs Global Minima
- Saddle Point and Non-Convex Behavior
- Visualization of surface topology and optimization trajectory

---

## âš™ï¸ Tech Stack

| Layer        | Tool / Library         |
|--------------|------------------------|
| GUI          | Streamlit              |
| Plots        | Matplotlib (3D, 2D)    |
| Animation    | FuncAnimation, Pillow  |
| Core Logic   | Python Classes & OOP   |
| Version      | Python 3.10+           |

---

## ğŸ–¥ï¸ Installation

```bash
git clone https://github.com/shivanshgupta2504/Maths-Projects.git
pip install -r requirements.txt
cd .\Visualizing_Gradient_Descent\
streamlit run main.py
